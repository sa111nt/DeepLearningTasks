{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebvqJaNU9bkH"
      },
      "source": [
        "# Elementy Inteligencji Obliczeniowej - Sieci Neuronowe\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Prowadzący:** Jakub Bednarek<br>\n",
        "**Kontakt:** jakub.bednarek@put.poznan.pl<br>\n",
        "**Materiały:** [Strona WWW](http://jakub.bednarek.pracownik.put.poznan.pl)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esyAESp_2Fq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f51fb4-0e70-47bd-f9ad-74ccd52d596f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0tVMrm99g5w"
      },
      "source": [
        "## Uwaga\n",
        "\n",
        "* **Aby wykonać polecenia należy najpierw przejść do trybu 'playground'. File -> Open in Playground Mode**\n",
        "* Nowe funkcje Colab pozwalają na autouzupełnianie oraz czytanie dokumentacji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5fCLe_r9mfo"
      },
      "source": [
        "## Technologie:\n",
        "\n",
        "Na zajęciach będziemy korzystać z języka Python oraz bibliotek **NumPy**, **Tensorflow**, IPython, Pillow, Matplotlib. Ponieważ:\n",
        "* obliczenia wykonywane przez sieci są masywne - przez co rozsądne jest aby korzystać z GPU,\n",
        "* nie każdy ma GPU w swoim komputerze,\n",
        "* nie każdy chce zostawać po godzinach w laboratoriach i korzystać z uczelnianych GPU,\n",
        "* konfiguracja Tensorflow na GPU potrafi być uciążliwa,\n",
        "\n",
        "będziemy korzystać głównie z Colab, na którym jest skonfigurowane środowisko wraz ze wszystkimi potrzebnymi składnikami oraz GPU.\n",
        "\n",
        "*Dla zainteresowanych: na stronie [Tensorflow](https://www.tensorflow.org/install/) znajduje się poradnik jak zainstalować bibliotekę na własnym komputerze. Popularnym podejściem do konfiguracji środowiska TensorFlow na własnej maszynie jest instalacja wirtualnego środowiska przy wykorzystaniu oprogramowania **Anaconda (Conda)**. Popularne IDE do Pythona, jak PyCharm posiadają obsługę środowisk stworzonych przez Condę. Można również korzystać z [NVIDIA-Docker2](https://github.com/NVIDIA/nvidia-docker) oraz gotowych obrazów systemu dostępnych po rejestracji na [NGC](https://ngc.nvidia.com).*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYcu0HmX9poV"
      },
      "source": [
        "## Cel ćwiczeń:\n",
        "\n",
        "* zapoznanie się z językiem Python oraz popularnymi bibliotekami do przetwarzania danych,\n",
        "* przedstawienie podstaw teoretycznych, na których oparte są sieci neuronowe,\n",
        "* implementacja podstawowych elementów sieci neuronowej (perceptron, funkcja aktywacji, funkcja straty, warstwa neuronów) i sposobu ich uczenia (**wsteczna propagacja błędu**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uhqCEJy5uuz"
      },
      "source": [
        "## NumPy\n",
        "\n",
        "NumPy jest biblioteką przeznaczoną do obliczeń o charakterze naukowym. Zawiera implementacje operacji na macierzach i wektorach, jak i bardziej zaawansowane funkcje typu transformata Fouriera.\n",
        "\n",
        "Aby korzystać z NumPy należy wykonać następującą instrukcję:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0DEDWrjBF8S"
      },
      "source": [
        "# import biblioteki NumPy i przypisanie aliasu ''np''\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHMxlATApJkY",
        "outputId": "a91d3654-54b8-4ded-f86c-d8c6a3b218ce"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 27 08:52:16 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WAkAImKBawh"
      },
      "source": [
        "Podstawowym typem danych w NumPy jest tablica, poniżej zostały zaprezentowane różne metody alokacji takich tablic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tOm6bXP60C3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e2a2e7-8a7c-4384-aa10-46962b593f53"
      },
      "source": [
        "# funkcja np.array() zmienia parametr (lista/tuple) na tablicę NumPy,\n",
        "# jednym z parametrów jest dtype który określa typ alokowanych danych (np.int32, np.float32, itp.)\n",
        "\n",
        "arr = np.array([1, 2, 3], dtype=np.int32)\n",
        "\n",
        "print('Tablica int:', arr, '\\n')\n",
        "\n",
        "arr = np.array([1, 2, 3], dtype=np.float32)\n",
        "print('Tablica float:', arr, '\\n')\n",
        "\n",
        "arr = np.zeros([2, 3], dtype=np.float32)\n",
        "print('Tablica zer:\\n', arr, '\\n')\n",
        "\n",
        "arr = np.ones([2, 3], dtype=np.float32)\n",
        "print('Tablica jedynek:\\n', arr, '\\n')\n",
        "\n",
        "arr = np.random.normal(5, 2, [5])\n",
        "print('5 wartości z rozkładu normalnego N(5, 2):\\n', arr, '\\n')\n",
        "\n",
        "arr = np.random.uniform(0, 2, [5])\n",
        "print('5 wartości losowych z przedziału <0, 2):\\n', arr, '\\n')\n",
        "\n",
        "arr = np.zeros_like(arr, dtype=np.float64)\n",
        "print('Tablica zer (float64) o takim samym rozmiarze co poprzednia tablica:\\n', arr, '\\n')\n",
        "\n",
        "arr = np.zeros_like(arr, dtype=np.uint8)\n",
        "print('Tablica zer (uint8) o takim samym rozmiarze co poprzednia tablica:\\n', arr, '\\n')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tablica int: [1 2 3] \n",
            "\n",
            "Tablica float: [1. 2. 3.] \n",
            "\n",
            "Tablica zer:\n",
            " [[0. 0. 0.]\n",
            " [0. 0. 0.]] \n",
            "\n",
            "Tablica jedynek:\n",
            " [[1. 1. 1.]\n",
            " [1. 1. 1.]] \n",
            "\n",
            "5 wartości z rozkładu normalnego N(5, 2):\n",
            " [3.13477526 2.85705125 7.24422273 3.86387055 6.97550052] \n",
            "\n",
            "5 wartości losowych z przedziału <0, 2):\n",
            " [0.05072303 1.84279679 1.51854964 1.18494647 0.50006319] \n",
            "\n",
            "Tablica zer (float64) o takim samym rozmiarze co poprzednia tablica:\n",
            " [0. 0. 0. 0. 0.] \n",
            "\n",
            "Tablica zer (uint8) o takim samym rozmiarze co poprzednia tablica:\n",
            " [0 0 0 0 0] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3nF2Ki5qUa3"
      },
      "source": [
        "Dodatkowo w bibliotece można znaleźć metody alokacji według pewnego wzorca jak *range* czy *linspace* (UWAGA: sprawdź, czy metody zwracają również przypadki krańcowe jako elementy tablicy):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxa5LFyAqfn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43abcdc0-e3a2-4b35-972e-d7037f317c51"
      },
      "source": [
        "# alokacja tablicy 10 wartości od 0 do 10 z równym krokiem\n",
        "arr = np.linspace(0, 10, 10)\n",
        "\n",
        "print('Linspace:', arr, '\\n')\n",
        "\n",
        "# alokacja tablicy z wartościami od 0 do 10 z krokiem 0.5\n",
        "arr = np.arange(0, 10, 0.5)\n",
        "\n",
        "print('ARange:', arr, '\\n')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linspace: [ 0.          1.11111111  2.22222222  3.33333333  4.44444444  5.55555556\n",
            "  6.66666667  7.77777778  8.88888889 10.        ] \n",
            "\n",
            "ARange: [0.  0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5 5.  5.5 6.  6.5 7.  7.5 8.  8.5\n",
            " 9.  9.5] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBXHfrIcrZrL"
      },
      "source": [
        "Kolejną przydatną funkcją jest funkcja **reshape** do zmiany wymiarów tablicy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHXn_4hvrkSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b33f6c2-2276-4f6d-8dd1-daffdb369b8d"
      },
      "source": [
        "# alokacja danych (tablica 25 wartości)\n",
        "arr = np.linspace(0, 10, 25)\n",
        "\n",
        "\n",
        "# zmiana rozmiaru z (25) na (5, 5):\n",
        "arr = np.reshape(arr, [5, 5])\n",
        "\n",
        "print(arr)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.          0.41666667  0.83333333  1.25        1.66666667]\n",
            " [ 2.08333333  2.5         2.91666667  3.33333333  3.75      ]\n",
            " [ 4.16666667  4.58333333  5.          5.41666667  5.83333333]\n",
            " [ 6.25        6.66666667  7.08333333  7.5         7.91666667]\n",
            " [ 8.33333333  8.75        9.16666667  9.58333333 10.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HriZKIT7FWdR"
      },
      "source": [
        "NumPy dostarcza implementacji wielu przydatnych operacji na tablicach. Poniżej zaprezentowane zostały podstawowe operacje:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XO7gXvxFqa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92faac8b-e681-4e8a-a105-780fe9a83377"
      },
      "source": [
        "# alokacja danych\n",
        "a = np.random.normal(0, 1, [3, 3])\n",
        "b = np.random.uniform(-1, 1, [3, 3])\n",
        "\n",
        "print('Tablica a:\\n', a, '\\n\\nTablica b:\\n', b, '\\n')\n",
        "\n",
        "# mnożenie element-wise:\n",
        "print('Mnożenie elementwise:\\n', np.multiply(a, b), '\\n')\n",
        "\n",
        "# mnożenie macierzy:\n",
        "print('Mnożenie macierzy:\\n', np.matmul(a, b), '\\n')\n",
        "\n",
        "# transpozycja tablicy\n",
        "print('Transpozycja:\\n', np.transpose(a, [1, 0]), '\\n')\n",
        "\n",
        "# potęgowanie:\n",
        "print('Potęgowanie:\\n', np.power(a, 2), '\\n')\n",
        "\n",
        "# broadcasted ops (są to operacje które wykonują pewien wzorzec dla wszystkich elementów):\n",
        "# np. dla macierzy o wymiarach (5, 10) możemy zdefiniować tablicę o wymiarach (1, 10)\n",
        "# wówczas podstawowe operacje spowodują, że dla każdego wiersza (5 wierszy) zostanie wykonana\n",
        "# taka operacja z wykorzystaniem 10 elementów drugiej tablicy\n",
        "# poniżej a ma rozmiar (3, 3), factor ma rozmiar (1, 3)\n",
        "factor = np.array([[1, 2, 3]], dtype=float)\n",
        "print('Broadcasted:\\n', np.multiply(a, factor), '\\n')\n",
        "print('Broadcasted add:\\n', a + factor, '\\n')\n",
        "print('Broadcasted subtract:\\n', a - factor, '\\n')\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tablica a:\n",
            " [[ 1.12102259 -1.20013421 -0.16319518]\n",
            " [ 1.11459176 -1.24138113 -0.98643943]\n",
            " [-0.62139319  0.14975166  0.3041127 ]] \n",
            "\n",
            "Tablica b:\n",
            " [[ 0.46639049  0.50857865  0.85799921]\n",
            " [-0.76475473 -0.89003245  0.58937875]\n",
            " [ 0.96606854 -0.64151536 -0.23186553]] \n",
            "\n",
            "Mnożenie elementwise:\n",
            " [[ 0.52283428 -0.61036264 -0.14002134]\n",
            " [-0.85238932  1.10486948 -0.58138644]\n",
            " [-0.60030841 -0.09606799 -0.07051325]] \n",
            "\n",
            "Mnożenie macierzy:\n",
            " [[ 1.28298486  1.74297876  0.29234223]\n",
            " [ 0.51621899  2.3045431   0.45339649]\n",
            " [-0.11054146 -0.64440412 -0.51540767]] \n",
            "\n",
            "Transpozycja:\n",
            " [[ 1.12102259  1.11459176 -0.62139319]\n",
            " [-1.20013421 -1.24138113  0.14975166]\n",
            " [-0.16319518 -0.98643943  0.3041127 ]] \n",
            "\n",
            "Potęgowanie:\n",
            " [[1.25669165 1.44032212 0.02663267]\n",
            " [1.24231478 1.5410271  0.97306274]\n",
            " [0.3861295  0.02242556 0.09248453]] \n",
            "\n",
            "Broadcasted:\n",
            " [[ 1.12102259 -2.40026842 -0.48958555]\n",
            " [ 1.11459176 -2.48276225 -2.95931828]\n",
            " [-0.62139319  0.29950332  0.9123381 ]] \n",
            "\n",
            "Broadcasted add:\n",
            " [[2.12102259 0.79986579 2.83680482]\n",
            " [2.11459176 0.75861887 2.01356057]\n",
            " [0.37860681 2.14975166 3.3041127 ]] \n",
            "\n",
            "Broadcasted subtract:\n",
            " [[ 0.12102259 -3.20013421 -3.16319518]\n",
            " [ 0.11459176 -3.24138113 -3.98643943]\n",
            " [-1.62139319 -1.85024834 -2.6958873 ]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLajGS7BH33s"
      },
      "source": [
        "Podstawowe operacje jak dodawanie, odejmowanie, mnożenie (element-wise), potęgowanie jest również dostępne korzystając z Python-owych operatorów (+, -, ...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMl2sLqvIY59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "222adf67-81b3-471b-b37c-a9dcf6b4f031"
      },
      "source": [
        "a = np.ones([3, 3])\n",
        "\n",
        "print(a, '\\n')\n",
        "print((a * 2) ** 2, '\\n')\n",
        "print(a + 10, '\\n')\n",
        "print(a * 10, '\\n')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]] \n",
            "\n",
            "[[4. 4. 4.]\n",
            " [4. 4. 4.]\n",
            " [4. 4. 4.]] \n",
            "\n",
            "[[11. 11. 11.]\n",
            " [11. 11. 11.]\n",
            " [11. 11. 11.]] \n",
            "\n",
            "[[10. 10. 10.]\n",
            " [10. 10. 10.]\n",
            " [10. 10. 10.]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AqptNHVsTWd"
      },
      "source": [
        "### Zadanie 0\n",
        "Wykonaj poniższe polecenia:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN2wZRBWsYYH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486740ca-d385-4de6-d3f6-806b863f9bfa"
      },
      "source": [
        "arr = np.linspace(0, 20, 20)\n",
        "\n",
        "#TODO: zmień kształt tablicy na (2, 10) - 2 wiersze po 10 wartości\n",
        "arr = arr.reshape(2, 10)\n",
        "print(arr, '\\n')\n",
        "\n",
        "#TODO: powiększ pierwszy wiersz o 2, drugi o 5. Operacja powinna być wykonana w 1 linii (zaalokuj zmienną a i wykorzystaj ją w operacji)\n",
        "a = np.array([[2], [5]])\n",
        "arr = arr + a\n",
        "\n",
        "print(arr, '\\n')\n",
        "\n",
        "#TODO: tablice NumPy można indeksować tak jak w innych językach programowania (np C, C++, Java)\n",
        "#TODO: ''wybierz'' z tablicy drugi wiersz, podnieś do kwadratu jego elementy i wyświetl funkcją print()\n",
        "arr_second_row_squared = arr[1] ** 2\n",
        "print(arr_second_row_squared)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.          1.05263158  2.10526316  3.15789474  4.21052632  5.26315789\n",
            "   6.31578947  7.36842105  8.42105263  9.47368421]\n",
            " [10.52631579 11.57894737 12.63157895 13.68421053 14.73684211 15.78947368\n",
            "  16.84210526 17.89473684 18.94736842 20.        ]] \n",
            "\n",
            "[[ 2.          3.05263158  4.10526316  5.15789474  6.21052632  7.26315789\n",
            "   8.31578947  9.36842105 10.42105263 11.47368421]\n",
            " [15.52631579 16.57894737 17.63157895 18.68421053 19.73684211 20.78947368\n",
            "  21.84210526 22.89473684 23.94736842 25.        ]] \n",
            "\n",
            "[241.06648199 274.86149584 310.87257618 349.09972299 389.54293629\n",
            " 432.20221607 477.07756233 524.16897507 573.47645429 625.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9W5ffp5IrnJ"
      },
      "source": [
        "### Zadanie 1\n",
        "Napisz funkcję liniową dla wielu zmiennych (**X** ma rozmiar *n* - liczba zmiennych), jednego współczynnika kierunkowego **a** i jednego wyrazu wolnego **b**. Następnie sprawdź, czy funkcja działa również, gdy dla każdej zmiennej przypiszemy osobne wartości a i b."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCRLIDLmI1yr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90e1dc2e-2a10-43d3-a031-8422834aab13"
      },
      "source": [
        "x = np.array([1, 2, 3, 4, 5])\n",
        "a = np.array(2)\n",
        "b = np.array(-1)\n",
        "\n",
        "def f1(x, a, b):\n",
        "  # TODO:\n",
        "  return a * x + b\n",
        "\n",
        "print(f1(x, a, b))\n",
        "\n",
        "a = np.array([1, 5, 2, 3, 1])\n",
        "b = np.array([5, 2, 3, 5, 1])\n",
        "\n",
        "print(f1(x, a, b))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 3 5 7 9]\n",
            "[ 6 12  9 17  6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCgv2OGMmjP3"
      },
      "source": [
        "Mechanizm polegający na wykonaniu tej samej operacji dla wszystkich wartości w danej osi nazywa się **broadcasting**. Przykładowo, wynikiem mnożenia dwóch zmiennych o wymiarach [20] i [1] będzie zmienna o wymiarze [20], dla zmiennych o wymiarach [20, 1] i [1, 20] wynikiem będzie zmienna o wymiarach [20, 20] (a więc każdy element z pierwszej zmiennej, przemnożony zostanie przez wszystkie wartości (**osobno**) z drugiej zmiennej."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_kYYr5vKIw4"
      },
      "source": [
        "### Zadanie 2\n",
        "\n",
        "Napisz funkcję, która będzie wykonywała kombinację liniową wektora zmiennych **X** oraz wektora **a**. Sprawdź, czy dla wielu wektorów **a** (kolumny tablicy **a**) funkcja będzie działała (jeśli nie, popraw funkcję).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwvXJ0GOL4Z3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21b89d7-2853-4d00-91fa-bf31e1b63d58"
      },
      "source": [
        "x = np.array([2, 3, 5])\n",
        "a = np.array([5, 1, 5])\n",
        "\n",
        "def f2(x, a):\n",
        "  # TODO:\n",
        "  return np.dot(x, a)\n",
        "\n",
        "print(f2(x, a))\n",
        "\n",
        "# for broadcast\n",
        "x = np.expand_dims(x, 0)\n",
        "\n",
        "a = np.array([\n",
        "    [5, 2],\n",
        "    [1, 2],\n",
        "    [5, 1]\n",
        "])\n",
        "\n",
        "print(f2(x, a))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38\n",
            "[[38 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj0Ayk0ZTI6A"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnpgaxS9Ux4L"
      },
      "source": [
        "## Perceptron (Neuron)\n",
        "\n",
        "Podstawowym elementem każdej sieci neuronowej jest neuron. Jest to jednostka która wykonuje następującą operację:\n",
        "\n",
        "$$z = \\sum_i x_i * w_i + b$$\n",
        "$$y = f(z)$$\n",
        "\n",
        "Gdzie $x_i$ to i-te *wejście* neuronu, $w_i$ to waga tego wejścia, natomiast $b$ to pewna stała. Wyjście funkcji liniowej $z$ jest następnie podawane na wejście pewnej funkcji aktywacji $f$.\n",
        "\n",
        "Istnieje wiele funkcji aktywacji takich jak:\n",
        "* skokowa (*funkcja progowa unipolarna*),\n",
        "$${\\displaystyle y(x)=\\left\\{{\\begin{matrix}0 & dla & x\\lt a\\\\1 & dla&x\\geq a\\\\\\end{matrix}}\\right.}$$\n",
        "* sigmoid,\n",
        "$$y(x)={\\frac {1}{1+e^{-\\beta x}}}$$\n",
        "* tangens hiperboliczny,\n",
        "$$y(x)={\\frac {2}{1+e^{-\\beta x}}}-1={\\frac {1-e^{-\\beta x}}{1+e^{-\\beta x}}}$$\n",
        "* relu,\n",
        "$$y(x)=max(0, x)$$\n",
        "\n",
        "\n",
        " Dla skokowej funkcji aktywacji zwyczajowo mówimy o perceptronie, dla innych funkcji aktywacji mówimy o neuronie.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Neuron wchodzi w skład wielu różnych elementów sieci neuronowej jak *konwolucja* czy *warstwa w pełni połączona* (fully connected).\n",
        "W przypadku warstwy fully connected wzór rozszerza się trywialnie na:\n",
        "\n",
        "$$z_j = \\sum_i x_i * w_{ij} + b_j$$\n",
        "$$y_j = f(z_j)$$\n",
        "\n",
        "Gdzie $j$ oznacza j-ty neuron.\n",
        "Jak widać powyżej, każdy z neuronów korzysta ze wszystkich wejść. Składnik $\\sum_i x_i * w_{ij}$ to kombinacja liniowa (patrz zadanie 2).\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Zadanie 3\n",
        "Zaimplementuj z wykorzystaniem biblioteki NumPy prosty neuron (linear) oraz następujące funkcje aktywacji: **sigmoid**, **relu**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz25l0F1aUiY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7868535-4ea2-4412-94d2-cacbe76139fc"
      },
      "source": [
        "def linear(x, w, b):\n",
        "  # TODO:\n",
        "  return x @ w + b\n",
        "\n",
        "\n",
        "def sigmoid(z, beta=0.5):\n",
        "  # TODO:\n",
        "  return 1 / (1 + np.exp(-beta * z))\n",
        "\n",
        "\n",
        "def relu(z):\n",
        "  # TODO:\n",
        "  return np.maximum(0, z)\n",
        "\n",
        "# UWAGA: rozmiar wejściowy (1, 5) ma dodaną jedynkę tylko ze względów obliczeniowych\n",
        "x = np.random.normal(0, 1, [1, 5])\n",
        "w = np.random.normal(0, 1, [5, 2])\n",
        "b = np.random.normal(0, 1, [2])\n",
        "\n",
        "z = linear(x, w, b)\n",
        "\n",
        "print('Linear activation:\\n', z, '\\n')\n",
        "print('Sigmoid activation:\\n', sigmoid(z), '\\n')\n",
        "print('Relu activation:\\n', relu(z), '\\n')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear activation:\n",
            " [[2.7986342  3.27414809]] \n",
            "\n",
            "Sigmoid activation:\n",
            " [[0.8020755  0.83713641]] \n",
            "\n",
            "Relu activation:\n",
            " [[2.7986342  3.27414809]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_FP5yglctfL"
      },
      "source": [
        "## Uczenie neuronów\n",
        "\n",
        "Podstawową metodą uczenia sieci neuronowych jest **metoda największego spadku**. Aby wykonać tę metodę niezbędne jest zdefiniowanie odpowiedniej **funkcji straty**. Funkcja straty określa jak bardzo nasza sieć myli się na danym przykładzie. Przykładowo jeśli neuron ma za zadanie odwzorować funkcję sinus to funkcją straty może być różnica pomiędzy estymowanym wyjściem neuronu ($y$) a pożądanym wyjściem ($y'$). Innym przykładem może byc klasyfikacja - sieć może estymować rozkład prawdopodobieństwa klas dla danego obrazka wejściowego (np. czy jest to kot czy pies), natomiast pożądanym wyjściem będzie **one-hot** wektor z zapalonym bitem na pozycji klasy prawdziwej. Wówczas jako funkcję straty możemy określić **cross-entropy**.\n",
        "\n",
        "Dla różnego rodzaju sieci (i ich przeznczenia) można korzystać z różnych funkcji strat. Do najpopularniejszych należą:\n",
        "* Mean Square Error:\n",
        "$$L = \\frac{1}{n}\\sum_i^n(y - y')^2$$\n",
        "gdzie $y$ to wyjście z neuronu (sieć), natomiast $y'$ to tzw. ground-truth - wartość, którą neuron (sieć) ma aproksymować,\n",
        "* Mean Absolute Error:\n",
        "$$L = \\frac{1}{n}\\sum_i^n |y - y'|$$\n",
        "* Cross-Entropy:\n",
        "$$L(p,q)=-\\sum _{x}p(x)\\,\\log q(x)$$\n",
        "gdzie p to pewien rozkład prawdopodobieństwa estymowany przez sieć, q to ground-truth rozkład prawdopodobieństwa. $x$ to przykład wejściowy.\n",
        "\n",
        "### Zadanie 4\n",
        "Zaimplementuj funkcję straty Mean Square Error (UWAGA: Mean Square Error jest liczony dla każdego przykładu (wiersza) osobno - przy obliczaniu średniej podaj odpowiedni parametr axis, wykorzystaj funkcję **np.mean**):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rit_pqx5B_VZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "83d23bd1-979c-43ea-9e7f-9a8b8640159c"
      },
      "source": [
        "y = np.array(\n",
        "    [[5, 1, 2],\n",
        "     [2, 2, 3]]\n",
        ")\n",
        "y_hat = np.array(\n",
        "    [[1, 5, 2],\n",
        "     [2, 3, 2]]\n",
        ")\n",
        "\n",
        "def mse(y, y_hat):\n",
        "  # TODO:\n",
        "  return np.mean((y - y_hat)**2, axis=1)\n",
        "\n",
        "print('Mean Square Error:', mse(y, y_hat))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Square Error: [10.66666667  0.66666667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmf9bVIdB9z0"
      },
      "source": [
        "#### Aktualizacja wag\n",
        "\n",
        "We wcześniejszych zadaniach można wyróżnić **zmienne uczące** oraz **propagowany sygnał**. Zmiennymi uczącymi nazywamy wszystkie parametry, które wchodzą w skład neuronów ale nie są podawane na wejściu. Z ich pomocą uczymy sieć aby produkowała pożądane wyjście na podstawie przykładów wejściowych. Przykłady wejściowe jak i rezultaty neuronów nazywamy propagowanym sygnałem. Jest to sygnał wykorzystany w procesie uczenia do określenia błędu jaki popełnił każdy z neuronów i w końcu do **obliczenia nowych wartości zmiennych**.\n",
        "\n",
        "Wyliczenie nowych wartości zmiennych przebiega zgodnie z zasadą:\n",
        "\n",
        "$$w_i' = w_i - \\mu \\frac{\\partial L}{\\partial w_i} $$\n",
        "\n",
        "Gdzie $\\mu$ to prędkość uczenia.\n",
        "\n",
        "Jak widać największy problem stanowi obliczenie pochodnej funkcji straty po danej wadze. W przypadku jednowarstwowej sieci neuronowej otrzymujemy (korzystając z chain-rule):\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w_i} = \\frac{\\partial L}{\\partial y} \\frac{\\partial y}{\\partial w_i}$$\n",
        "\n",
        "Wówczas ponownie korzystając z chain rule:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w_i} = \\frac{\\partial L}{\\partial y} \\frac{\\partial y}{\\partial w_i} = \\frac{\\partial L}{\\partial y} \\frac{\\partial y}{\\partial z}\\frac{\\partial z}{\\partial w_i}$$\n",
        "\n",
        "Gdzie $\\frac{\\partial y}{\\partial z}$ to pochodna funkcji aktywacji, natomiast $z = \\sum_iw_ix_i + b$, dla której pochodna jest równa $x_i$, stąd:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial w_i} = \\frac{\\partial L}{\\partial y} f'(z) x_i$$\n",
        "\n",
        "Końcowo:\n",
        "\n",
        "$$w_i' = w_i - \\mu \\frac{\\partial L}{\\partial y} f'(z) x_i $$\n",
        "\n",
        "*Wskazówka do kolejnych zadań:*\n",
        "\n",
        "* Zastępując $\\frac{\\partial L}{\\partial y} f'(z) = \\delta$ zwór można zapisać jako:\n",
        "$$w_i' = w_i - \\mu \\delta x_i $$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Zadanie 5\n",
        "Zaimplementuj pochodne funkcji aktywacji: **relu** oraz **sigmoid** oraz funkcji liniowej. Dodatkowo zaimplementuj pochodną funkcji straty **Mean Square Error**.\n",
        "\n",
        "**Podpowiedź:** tablice w NumPy można indeksować tablicą bool-ową. Przykład:\n",
        "\n",
        "\n",
        "```\n",
        "a = np.random.normal(0, 1, [3, 3])\n",
        "a[a<0] = -1\n",
        "a[a>=0] = 1\n",
        "```\n",
        "\n",
        "Powyższy przykład ustawia wartości w tablicy na -1, gdzie poprzednio była wartość ujemna, natomiast dla wartości dodatnich (lub 0) ustawia wartość 1.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWQXvZOZ_2OS"
      },
      "source": [
        "def d_relu(z):\n",
        "  return (z > 0).astype(z.dtype)\n",
        "\n",
        "\n",
        "def d_sigmoid(z, beta=0.5):\n",
        "  s = sigmoid(z, beta)\n",
        "  return beta * s * (1 - s)\n",
        "\n",
        "\n",
        "def d_linear(x, w, b):\n",
        "  return x.T\n",
        "\n",
        "\n",
        "def d_mse(y, y_hat):\n",
        "  num_outputs = y.shape[1]\n",
        "  return 2 * (y - y_hat) / num_outputs"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U2VS0EAAQ2W"
      },
      "source": [
        "### Zadanie 6\n",
        "Zaimplementuj funkcję obliczającą nową wartość dla zmiennych **w**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3twSteMAh_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70f08d7-8f87-4146-8f89-4f2e60589b36"
      },
      "source": [
        "mu = 1e-2\n",
        "\n",
        "# UWAGA: rozmiar wejściowy (1, 5) ma dodaną jedynkę tylko ze względów obliczeniowych\n",
        "x = np.random.normal(0, 1, [1, 5])\n",
        "w = np.random.normal(0, 1, [5, 1])\n",
        "b = np.random.normal(0, 1, [1])\n",
        "\n",
        "y_hat = np.ones([1, 1], dtype=np.float32)\n",
        "\n",
        "z = linear(x, w, b)\n",
        "y = relu(z)\n",
        "\n",
        "print('Z:\\n', z, '\\n')\n",
        "print('Y:\\n', y)\n",
        "\n",
        "delta = d_relu(z) * d_mse(y, y_hat)\n",
        "\n",
        "print('Delta:\\n', delta, '\\n')\n",
        "\n",
        "\n",
        "def update(variable, mu, delta, x):\n",
        "  return variable - mu * (x.T @ delta)\n",
        "\n",
        "\n",
        "w_new = update(w, mu, delta, x)\n",
        "\n",
        "print('Wagi przed:\\n', w, '\\n')\n",
        "print('Wagi po:\\n', w_new)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z:\n",
            " [[-7.02861547]] \n",
            "\n",
            "Y:\n",
            " [[0.]]\n",
            "Delta:\n",
            " [[-0.]] \n",
            "\n",
            "Wagi przed:\n",
            " [[ 0.60006265]\n",
            " [ 0.48201128]\n",
            " [-0.25104015]\n",
            " [-2.50474729]\n",
            " [ 0.52978437]] \n",
            "\n",
            "Wagi po:\n",
            " [[ 0.60006265]\n",
            " [ 0.48201128]\n",
            " [-0.25104015]\n",
            " [-2.50474729]\n",
            " [ 0.52978437]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbVuSc6DFIUA"
      },
      "source": [
        "### Zadanie 7*\n",
        "Wyznacz regułę aktualizacji dla zmiennych **b**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83ef15d6",
        "outputId": "6d96c0f2-c67e-45d5-c479-3522d6fade1e"
      },
      "source": [
        "# Używając mu, delta i b z wcześniejszego z Zadania 6\n",
        "# mu = 1e-2\n",
        "# delta - obliczona w Zadaniu 6\n",
        "# b - z Zadania 6\n",
        "\n",
        "b_new = b - mu * delta\n",
        "\n",
        "print('Bias przed aktualizacją (b):\\n', b, '\\n')\n",
        "print('Bias po aktualizacji (b_new):\\n', b_new, '\\n')\n",
        "\n",
        "# Możemy również zdefiniować ogólną funkcję do aktualizacji biasu\n",
        "def update_bias(bias_variable, learning_rate, error_delta):\n",
        "  return bias_variable - learning_rate * error_delta\n",
        "\n",
        "b_new_func = update_bias(b, mu, delta)\n",
        "print('Bias po aktualizacji (przez funkcję):\\n', b_new_func)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bias przed aktualizacją (b):\n",
            " [-0.28530286] \n",
            "\n",
            "Bias po aktualizacji (b_new):\n",
            " [[-0.28530286]] \n",
            "\n",
            "Bias po aktualizacji (przez funkcję):\n",
            " [[-0.28530286]]\n"
          ]
        }
      ]
    }
  ]
}